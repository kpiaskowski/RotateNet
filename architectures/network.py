from tensorflow.contrib.layers import xavier_initializer
import tensorflow as tf

def encoder(inputs, activation, is_training):
    """Encoder part of the network. Uses shortcut connections for Unet architecture"""
    with tf.variable_scope('encoder', reuse=tf.AUTO_REUSE, initializer=xavier_initializer()):
        batch_size = tf.shape(inputs)[0]

        conv1 = tf.layers.conv2d(inputs, 48, 3, padding='same', activation=None)
        conv1 = tf.layers.batch_normalization(conv1, training=is_training, fused=True)
        conv1 = activation(conv1)
        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)

        shortcut1 = tf.get_variable('shortcut1', shape=[1, 64, 64, 48], dtype=tf.float32)
        shortcut1 = tf.tile(shortcut1, [batch_size, 1, 1, 1])
        shortcut1 = tf.nn.sigmoid(conv1 * shortcut1)

        conv2 = tf.layers.conv2d(conv1, 92, 3, padding='same', activation=None)
        conv2 = tf.layers.batch_normalization(conv2, training=is_training, fused=True)
        conv2 = activation(conv2)
        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)

        shortcut2 = tf.get_variable('shortcut2', shape=[1, 32, 32, 92], dtype=tf.float32)
        shortcut2 = tf.tile(shortcut2, [batch_size, 1, 1, 1])
        shortcut2 = tf.nn.sigmoid(conv2 * shortcut2)

        conv3 = tf.layers.conv2d(conv2, 256, 3, padding='same', activation=None, name='econv3')
        conv3 = tf.layers.batch_normalization(conv3, training=is_training, fused=True)
        conv3 = activation(conv3)
        conv3 = tf.layers.max_pooling2d(conv3, 2, 2)

        shortcut3 = tf.get_variable('shortcut3', shape=[1, 16, 16, 256], dtype=tf.float32)
        shortcut3 = tf.tile(shortcut3, [batch_size, 1, 1, 1])
        shortcut3 = tf.nn.sigmoid(conv3 * shortcut3)

        conv4 = tf.layers.conv2d(conv3, 256, 3, padding='same', activation=None)
        conv4 = tf.layers.batch_normalization(conv4, training=is_training, fused=True)
        conv4 = activation(conv4)
        conv4 = tf.layers.max_pooling2d(conv4, 2, 2)

        conv5 = tf.layers.conv2d(conv4, 256, 3, padding='same', activation=None)
        conv5 = tf.layers.batch_normalization(conv5, training=is_training, fused=True)
        conv5 = activation(conv5)
        conv5 = tf.layers.max_pooling2d(conv5, 2, 2)

        conv6 = tf.layers.conv2d(conv5, 256, 3, padding='same', activation=None)
        conv6 = tf.layers.batch_normalization(conv6, training=is_training, fused=True)
        conv6 = activation(conv6)
        conv6 = tf.layers.max_pooling2d(conv6, 2, 2)

        conv_features = tf.layers.flatten(conv6)
        return conv_features, shortcut1, shortcut2, shortcut3


def latent_space(conv_features, angles, activation):
    """Merges features extracted by conv layers with information about desired output angles"""
    dense1 = tf.layers.dense(angles, 512)
    dense1 = tf.layers.dense(dense1, 512, activation)

    dense2 = tf.concat([conv_features, dense1], -1)
    dense2 = tf.layers.dense(dense2, 1024, activation)
    dense2 = tf.layers.dense(dense2, 16384, activation)

    return dense2


def decoder(merged_view_conv, activation, is_training, shortcut1, shortcut2, shortcut3):
    """Decoder network. Uses shortcuts generated by encoder"""
    with tf.variable_scope('decoder', reuse=tf.AUTO_REUSE, initializer=xavier_initializer()):

        pre_conv = tf.reshape(merged_view_conv, [-1, 8, 8, 256])
        pre_conv = tf.image.resize_images(pre_conv, (16, 16))
        pre_conv = tf.concat([pre_conv, shortcut3], axis=-1)

        conv1 = tf.layers.conv2d(pre_conv, 256, 3, padding='same', activation=None)
        conv1 = tf.layers.batch_normalization(conv1, training=is_training, fused=True)
        conv1 = activation(conv1)
        conv1 = tf.image.resize_images(conv1, (32, 32))
        conv1 = tf.concat([conv1, shortcut2], axis=-1)

        conv2 = tf.layers.conv2d(conv1, 92, 3, padding='same', activation=None)
        conv2 = tf.layers.batch_normalization(conv2, training=is_training, fused=True)
        conv2 = activation(conv2)
        conv2 = tf.image.resize_images(conv2, (64, 64))
        conv2 = tf.concat([conv2, shortcut1], axis=-1)

        conv3 = tf.layers.conv2d(conv2, 48, 3, padding='same', activation=None)
        conv3 = tf.layers.batch_normalization(conv3, training=is_training, fused=True)
        conv3 = activation(conv3)
        conv3 = tf.image.resize_images(conv3, (128, 128))

        generated_rgb = tf.layers.conv2d(conv3, 3, 3, padding='same', activation=None)

        return generated_rgb